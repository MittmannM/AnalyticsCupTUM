{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ANAC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# data read-in"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew, kurtosis, probplot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:44:20.214899Z",
     "start_time": "2024-01-15T12:44:20.207693Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:44:20.226340Z",
     "start_time": "2024-01-15T12:44:20.217452Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z0/24mzs0z565s6qpzztgbdrj780000gn/T/ipykernel_51887/3884275055.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews_csv = pd.read_csv(\"reviews.csv\").copy()\n"
     ]
    }
   ],
   "source": [
    "diet_csv = pd.read_csv(\"diet.csv\").copy()\n",
    "recipes_csv = pd.read_csv(\"recipes.csv\").copy()\n",
    "requests_csv = pd.read_csv(\"requests.csv\").copy()\n",
    "reviews_csv = pd.read_csv(\"reviews.csv\").copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:44:20.636313Z",
     "start_time": "2024-01-15T12:44:20.228358Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Basics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "diet_csv.rename(columns= {\"AuthorId\" : \"CustomerId\"}, inplace=True)\n",
    "reviews_csv.rename(columns= {\"AuthorId\" : \"CustomerId\"}, inplace=True)\n",
    "\n",
    "diet_csv[\"Diet\"] = diet_csv[\"Diet\"].astype(\"category\")\n",
    "\n",
    "recipes_csv[\"RecipeCategory\"] = recipes_csv[\"RecipeCategory\"].astype(\"category\")\n",
    "\n",
    "requests_csv.rename(columns= {\n",
    "    \"AuthorId\" : \"CustomerId\",\n",
    "    \"Time\": \"MaxTime\"\n",
    "}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:44:20.651455Z",
     "start_time": "2024-01-15T12:44:20.638426Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Handing missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "diet_csv['Diet'].fillna('Vegetarian', inplace=True)\n",
    "\n",
    "\n",
    "# with mean\n",
    "recipesServings_mean = recipes_csv['RecipeServings'].mean()\n",
    "#fill na rows with the mean\n",
    "recipes_csv['RecipeServings'].fillna(recipesServings_mean, inplace=True)\n",
    "recipesServings_mean = recipes_csv['RecipeServings'].mean()\n",
    "\n",
    "\n",
    "\n",
    "mapping_cal = {1: 1, 0.0: 0}\n",
    "requests_csv['HighCalories'] = requests_csv['HighCalories'].map(mapping_cal).astype('category')\n",
    "\n",
    "mapping_protein = {'Yes': 'Yes', 'Indifferent': 'Indifferent', 'No': 'No', }\n",
    "requests_csv['HighProtein'] = requests_csv['HighProtein'].map(mapping_protein).astype('category')\n",
    "\n",
    "requests_csv['LowFat'] = requests_csv['LowFat'].astype('category')\n",
    "\n",
    "mapping_sugar = {'1': 'Yes', 'Indifferent': 'Indifferent', '0': 'No', }\n",
    "requests_csv['LowSugar'] = requests_csv['LowSugar'].map(mapping_sugar).astype('category')\n",
    "\n",
    "requests_csv['HighFiber'] = requests_csv['HighFiber'].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:44:20.676595Z",
     "start_time": "2024-01-15T12:44:20.651720Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge tables\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      CustomerId  RecipeId   Like  Age      MaxTime HighCalories LowFat  \\\n0       1000036C    320576  False   50   119.024930            0      0   \n1       1000216B    189335  False   78  1199.386790            0      0   \n2       1000221A    133043  False   25   362.152341            0      0   \n3       1000221A     90537  False   25  1198.957497            0      0   \n4       1000221A    334314  False   25  5400.036634            1      0   \n...          ...       ...    ...  ...          ...          ...    ...   \n97376    999595E    338070  False   31  3899.421310            0      1   \n97377    999774A     29002  False   57  2402.372535            0      0   \n97378    999774A    159252  False   57  5999.598903            0      0   \n97379    999774A      1171   True   57   480.233207            1      0   \n97380    999917E    169413  False   28  3600.387748            0      0   \n\n      HighFiber                                     Name  CookTime  ...  \\\n0             1                               Downeaster         0  ...   \n1             1            Thai Rice Soup (Kao Tome Gai)       600  ...   \n2             1     Lemon and Thyme Marinade for Poultry        60  ...   \n3             1                         Black Bean Salsa         0  ...   \n4             0                        Irish  Soda Bread      3600  ...   \n...         ...                                      ...       ...  ...   \n97376         0                 Pumpkin Cake Mix Dessert      3000  ...   \n97377         0                   Summer Corkscrew Pasta      1200  ...   \n97378         0  Chili, Kaffir Lime and Lemongrass Jelly      4800  ...   \n97379         0                     Kahlua Hot Chocolate       360  ...   \n97380         0               Inglenook Spoon Bread Cake      2700  ...   \n\n       Diet_Vegan Diet_Vegetarian RecipeCategory_Bread  \\\n0           False            True                False   \n1           False            True                False   \n2           False            True                False   \n3           False            True                False   \n4           False            True                 True   \n...           ...             ...                  ...   \n97376       False            True                False   \n97377       False            True                False   \n97378       False            True                False   \n97379       False            True                False   \n97380       False            True                 True   \n\n       RecipeCategory_Breakfast  RecipeCategory_Lunch  \\\n0                         False                 False   \n1                         False                 False   \n2                         False                 False   \n3                          True                 False   \n4                         False                 False   \n...                         ...                   ...   \n97376                     False                 False   \n97377                     False                 False   \n97378                     False                 False   \n97379                     False                 False   \n97380                     False                 False   \n\n       RecipeCategory_One dish meal  RecipeCategory_Other  \\\n0                             False                 False   \n1                             False                  True   \n2                             False                  True   \n3                             False                 False   \n4                             False                 False   \n...                             ...                   ...   \n97376                         False                  True   \n97377                         False                  True   \n97378                         False                  True   \n97379                         False                 False   \n97380                         False                 False   \n\n       RecipeCategory_Soup  HighProtein_Yes  LowSugar_No  \n0                    False            False        False  \n1                    False             True         True  \n2                    False             True        False  \n3                    False             True         True  \n4                    False            False         True  \n...                    ...              ...          ...  \n97376                False            False        False  \n97377                False            False        False  \n97378                False             True         True  \n97379                False             True         True  \n97380                False            False        False  \n\n[97381 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CustomerId</th>\n      <th>RecipeId</th>\n      <th>Like</th>\n      <th>Age</th>\n      <th>MaxTime</th>\n      <th>HighCalories</th>\n      <th>LowFat</th>\n      <th>HighFiber</th>\n      <th>Name</th>\n      <th>CookTime</th>\n      <th>...</th>\n      <th>Diet_Vegan</th>\n      <th>Diet_Vegetarian</th>\n      <th>RecipeCategory_Bread</th>\n      <th>RecipeCategory_Breakfast</th>\n      <th>RecipeCategory_Lunch</th>\n      <th>RecipeCategory_One dish meal</th>\n      <th>RecipeCategory_Other</th>\n      <th>RecipeCategory_Soup</th>\n      <th>HighProtein_Yes</th>\n      <th>LowSugar_No</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>320576</td>\n      <td>False</td>\n      <td>50</td>\n      <td>119.024930</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Downeaster</td>\n      <td>0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>189335</td>\n      <td>False</td>\n      <td>78</td>\n      <td>1199.386790</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Thai Rice Soup (Kao Tome Gai)</td>\n      <td>600</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>133043</td>\n      <td>False</td>\n      <td>25</td>\n      <td>362.152341</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Lemon and Thyme Marinade for Poultry</td>\n      <td>60</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>90537</td>\n      <td>False</td>\n      <td>25</td>\n      <td>1198.957497</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Black Bean Salsa</td>\n      <td>0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>334314</td>\n      <td>False</td>\n      <td>25</td>\n      <td>5400.036634</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Irish  Soda Bread</td>\n      <td>3600</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97376</th>\n      <td>999595E</td>\n      <td>338070</td>\n      <td>False</td>\n      <td>31</td>\n      <td>3899.421310</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Pumpkin Cake Mix Dessert</td>\n      <td>3000</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>97377</th>\n      <td>999774A</td>\n      <td>29002</td>\n      <td>False</td>\n      <td>57</td>\n      <td>2402.372535</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Summer Corkscrew Pasta</td>\n      <td>1200</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>97378</th>\n      <td>999774A</td>\n      <td>159252</td>\n      <td>False</td>\n      <td>57</td>\n      <td>5999.598903</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Chili, Kaffir Lime and Lemongrass Jelly</td>\n      <td>4800</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>97379</th>\n      <td>999774A</td>\n      <td>1171</td>\n      <td>True</td>\n      <td>57</td>\n      <td>480.233207</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Kahlua Hot Chocolate</td>\n      <td>360</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>97380</th>\n      <td>999917E</td>\n      <td>169413</td>\n      <td>False</td>\n      <td>28</td>\n      <td>3600.387748</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Inglenook Spoon Bread Cake</td>\n      <td>2700</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>97381 rows Ã— 34 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge diet + review\n",
    "reviews_csv[\"Like\"] = reviews_csv[\"Like\"].astype(\"category\")\n",
    "reviews_csv = reviews_csv.drop(\"Rating\", axis=1)\n",
    "reviews_csv.dropna(subset=[\"Like\"], inplace=True) # note: now the entries are reduced to 97381 entries\n",
    "reviews_csv = reviews_csv.drop(\"TestSetId\", axis=1)\n",
    "review_with_diet = pd.merge(reviews_csv, diet_csv, on=\"CustomerId\", how=\"inner\") # 97381 entries\n",
    "#merge diet + review + request\n",
    "review_diet_with_request = pd.merge(review_with_diet, requests_csv, on=[\"CustomerId\", \"RecipeId\"], how=\"inner\") # 97381 entries\n",
    "df = pd.merge(review_diet_with_request, recipes_csv, on='RecipeId', how='left')\n",
    "df = pd.get_dummies(df, columns=['Diet', 'RecipeCategory', 'HighProtein', 'LowSugar'], drop_first=True) \n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:44:20.826975Z",
     "start_time": "2024-01-15T12:44:20.684250Z"
    }
   },
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot continuous variables vs Like"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Handling outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "maxtime_val = df['MaxTime'].max()\n",
    "outliers = df['MaxTime'] >= maxtime_val\n",
    "median_without_outliers = df.loc[~outliers, 'MaxTime'].median()\n",
    "df.loc[outliers, 'MaxTime'] = median_without_outliers\n",
    "\n",
    "maxtime_val = df['PrepTime'].max()\n",
    "outliers = df['PrepTime'] >= maxtime_val\n",
    "median_without_outliers = df.loc[~outliers, 'PrepTime'].median()\n",
    "df.loc[outliers, 'PrepTime'] = median_without_outliers\n",
    "outliers = (df['Like'] == True) & (df['PrepTime'] > 3000000)\n",
    "df.loc[outliers, 'PrepTime'] = median_without_outliers\n",
    "\n",
    "outliers = (df['Like'] == True) & (df['Calories'] > 30000)\n",
    "median_without_outliers = df.loc[~outliers, 'Calories'].median()\n",
    "df.loc[outliers, 'Calories'] = median_without_outliers\n",
    "\n",
    "outliers = df['FatContent'] > 25000\n",
    "median_without_outliers = df.loc[~outliers, 'FatContent'].median()\n",
    "df.loc[outliers, 'FatContent'] = median_without_outliers\n",
    "outliers = (df['Like'] == True) & (df['FatContent'] > 2500)\n",
    "df.loc[outliers, 'FatContent'] = median_without_outliers\n",
    "\n",
    "outliers = df['SaturatedFatContent'] > 12000\n",
    "median_without_outliers = df.loc[~outliers, 'SaturatedFatContent'].median()\n",
    "df.loc[outliers, 'SaturatedFatContent'] = median_without_outliers\n",
    "\n",
    "outliers = df['CholesterolContent'] > 35000\n",
    "median_without_outliers = df.loc[~outliers, 'CholesterolContent'].median()\n",
    "df.loc[outliers, 'CholesterolContent'] = median_without_outliers\n",
    "outliers = (df['Like'] == True) & (df['CholesterolContent'] > 10000)\n",
    "df.loc[outliers, 'CholesterolContent'] = median_without_outliers\n",
    "\n",
    "outliers = (df['Like'] == True) & (df['CarbohydrateContent'] > 4000)\n",
    "median_without_outliers = df.loc[~outliers, 'CarbohydrateContent'].median()\n",
    "df.loc[outliers, 'CarbohydrateContent'] = median_without_outliers\n",
    "\n",
    "outliers = (df['Like'] == True) & (df['FiberContent'] > 400)\n",
    "median_without_outliers = df.loc[~outliers, 'FiberContent'].median()\n",
    "df.loc[outliers, 'FiberContent'] = median_without_outliers\n",
    "\n",
    "outliers = (df['Like'] == True) & (df['SugarContent'] > 4000)\n",
    "median_without_outliers = df.loc[~outliers, 'SugarContent'].median()\n",
    "df.loc[outliers, 'SugarContent'] = median_without_outliers\n",
    "\n",
    "outliers = df['ProteinContent'] > 17500\n",
    "median_without_outliers = df.loc[~outliers, 'ProteinContent'].median()\n",
    "df.loc[outliers, 'ProteinContent'] = median_without_outliers\n",
    "outliers = (df['Like'] == True) & (df['ProteinContent'] > 3000)\n",
    "df.loc[outliers, 'ProteinContent'] = median_without_outliers\n",
    "\n",
    "outliers = df['RecipeServings'] > 30000\n",
    "median_without_outliers = df.loc[~outliers, 'RecipeServings'].median()\n",
    "df.loc[outliers, 'RecipeServings'] = median_without_outliers\n",
    "outliers = (df['Like'] == True) & (df['RecipeServings'] > 400)\n",
    "df.loc[outliers, 'RecipeServings'] = median_without_outliers\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:44:20.857464Z",
     "start_time": "2024-01-15T12:44:20.828177Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data standardization and dimensional reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fit Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = df.drop(['CustomerId', 'RecipeId', 'Like', 'Name', 'RecipeIngredientQuantities', 'RecipeIngredientParts', 'RecipeYield', 'RecipeCategory_Other', ], axis=1)\n",
    "y = df['Like']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:44:20.871653Z",
     "start_time": "2024-01-15T12:44:20.851860Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y,\n",
    "                     test_size=0.3,\n",
    "                     shuffle=True,\n",
    "                     random_state=3)\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:44:20.872407Z",
     "start_time": "2024-01-15T12:44:20.856687Z"
    }
   },
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model__learning_rate': 0.6, 'model__n_estimators': 300, 'pca__n_components': 15}\n",
      "Best CV score: 0.6347210950798907\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "columns_to_standardized = ['Calories', 'FatContent', 'SaturatedFatContent', 'CholesterolContent', 'SodiumContent', 'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent', 'MaxTime', 'PrepTime', 'CookTime', 'Age', 'RecipeServings']\n",
    "df[columns_to_standardized] = scaler.fit_transform(df[columns_to_standardized])\n",
    "\n",
    "transform_pca = PCA()  \n",
    "principal_components = transform_pca.fit_transform(df[columns_to_standardized])\n",
    "\n",
    "train_model = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", scaler),\n",
    "    (\"pca\", transform_pca),\n",
    "    (\"model\", train_model)\n",
    "])\n",
    "\n",
    "parameter_grid_preprocessing = {\n",
    "    \"pca__n_components\": [10, 15, 20],\n",
    "}\n",
    "\n",
    "parameter_grid_gradient_boosting = {\n",
    "    \"model__n_estimators\": [300],\n",
    "    \"model__learning_rate\": [0.6]\n",
    "}\n",
    "\n",
    "meta_parameter_grid = [parameter_grid_gradient_boosting]\n",
    "\n",
    "meta_parameter_grid = [{**parameter_grid_preprocessing, **model_grid} for model_grid in meta_parameter_grid]\n",
    "\n",
    "# Create GridSearchCV\n",
    "search = GridSearchCV(pipeline,\n",
    "                      meta_parameter_grid,\n",
    "                      scoring=\"balanced_accuracy\",\n",
    "                      n_jobs=2,\n",
    "                      cv=5,\n",
    "                      error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# Perform the grid search on your training data\n",
    "search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Display the best parameters and CV score\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best CV score:\", search.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T12:57:09.714920Z",
     "start_time": "2024-01-15T12:47:51.857002Z"
    }
   },
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model__learning_rate': 0.6, 'model__n_estimators': 300}\n",
      "Best CV score: 0.6977874514746663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Standardize the specified columns\n",
    "scaler = StandardScaler()\n",
    "columns_to_standardized = ['Calories', 'FatContent', 'SaturatedFatContent', 'CholesterolContent', 'SodiumContent', 'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent', 'MaxTime', 'PrepTime', 'CookTime', 'Age', 'RecipeServings']\n",
    "df[columns_to_standardized] = scaler.fit_transform(df[columns_to_standardized])\n",
    "\n",
    "# Create the GradientBoostingClassifier\n",
    "train_model = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "# Create the pipeline without PCA\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"model\", train_model)\n",
    "])\n",
    "\n",
    "# Specify parameter grids\n",
    "parameter_grid_gradient_boosting = {\n",
    "    \"model__n_estimators\": [300],\n",
    "    \"model__learning_rate\": [0.6]\n",
    "}\n",
    "\n",
    "# Meta-parameter grid\n",
    "meta_parameter_grid = [parameter_grid_gradient_boosting]\n",
    "\n",
    "meta_parameter_grid = [{**model_grid} for model_grid in meta_parameter_grid]\n",
    "\n",
    "# Create GridSearchCV\n",
    "search = GridSearchCV(pipeline,\n",
    "                      meta_parameter_grid,\n",
    "                      scoring=\"balanced_accuracy\",\n",
    "                      n_jobs=2,\n",
    "                      cv=5,\n",
    "                      error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# Perform the grid search on your training data\n",
    "search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Display the best parameters and CV score\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best CV score:\", search.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T13:03:36.293825Z",
     "start_time": "2024-01-15T13:01:36.210790Z"
    }
   },
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
