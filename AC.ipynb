{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T12:32:44.848362500Z",
     "start_time": "2024-05-16T12:32:43.971558300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T12:32:47.537781200Z",
     "start_time": "2024-05-16T12:32:47.511757300Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T12:32:50.374622400Z",
     "start_time": "2024-05-16T12:32:49.296969200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maximilian Mittmann\\AppData\\Local\\Temp\\ipykernel_13380\\1690002940.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews_csv = pd.read_csv(\"reviews.csv\").copy()\n"
     ]
    }
   ],
   "source": [
    "diet_csv = pd.read_csv(\"diet.csv\").copy()\n",
    "recipes_csv = pd.read_csv(\"recipes.csv\").copy()\n",
    "requests_csv = pd.read_csv(\"requests.csv\").copy()\n",
    "reviews_csv = pd.read_csv(\"reviews.csv\").copy()\n",
    "food = pd.read_csv(\"DietMatchesRecipe.csv\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           AuthorId  RecipeId  Rating   Like  TestSetId\n0          2492191A     33671     2.0    NaN        1.0\n1       2002019979A     92647     2.0    NaN        2.0\n2           408594E    161770     NaN    NaN        3.0\n3       2001625557E    108231     2.0    NaN        4.0\n4       2001427116E     71109     NaN    NaN        5.0\n...             ...       ...     ...    ...        ...\n140190      999595E    338070     2.0  False        NaN\n140191      999774A     29002     2.0  False        NaN\n140192      999774A    159252     NaN  False        NaN\n140193      999774A      1171     2.0   True        NaN\n140194      999917E    169413     2.0  False        NaN\n\n[140195 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2492191A</td>\n      <td>33671</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2002019979A</td>\n      <td>92647</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>408594E</td>\n      <td>161770</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001625557E</td>\n      <td>108231</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001427116E</td>\n      <td>71109</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999595E</td>\n      <td>338070</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999774A</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>999917E</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:32:51.330516200Z",
     "start_time": "2024-05-16T12:32:51.258442500Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# merge diet + request\n",
    "request_with_diet = pd.merge(diet_csv, requests_csv, how=\"inner\", on=\"AuthorId\")\n",
    "# merge diet + request + recipe\n",
    "request_with_diet_and_recipe = pd.merge(recipes_csv, request_with_diet, how=\"inner\", on=\"RecipeId\")\n",
    "# merge diet + request + recipe + review\n",
    "df_mid = pd.merge(reviews_csv, request_with_diet_and_recipe, how=\"inner\", on=[\"AuthorId\", \"RecipeId\"])\n",
    "\n",
    "df = pd.merge(df_mid, food, how=\"inner\", on=[\"AuthorId\", \"RecipeId\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:32:53.136720700Z",
     "start_time": "2024-05-16T12:32:52.485128900Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# drop na diet column\n",
    "df = df.dropna(subset=['Diet'])\n",
    "# Rename AuthorId column\n",
    "df.rename(columns= {\n",
    "    \"AuthorId\" : \"CustomerId\",\n",
    "    \"Time\": \"MaxTime\"\n",
    "}, inplace=True)\n",
    "\n",
    "df[\"Like\"] = df[\"Like\"].astype(\"boolean\")\n",
    "# Change types into category and mapping values\n",
    "df[\"Diet\"] = df[\"Diet\"].astype(\"category\")\n",
    "\n",
    "df[\"RecipeCategory\"] = df[\"RecipeCategory\"].astype(\"category\")\n",
    "\n",
    "mapping_cal = {1: 'Yes', 0.0: 'No'}\n",
    "df['HighCalories'] = df['HighCalories'].map(mapping_cal).astype('category')\n",
    "\n",
    "mapping_protein = {'Yes': 'Yes', 'Indifferent': 'Indifferent', 'No': 'No' }\n",
    "df['HighProtein'] = df['HighProtein'].map(mapping_protein).astype('category')\n",
    "\n",
    "mapping_cal = {1: 'Yes', 0.0: 'No'}\n",
    "df['LowFat'] = df['LowFat'].map(mapping_cal).astype('category')\n",
    "\n",
    "mapping_sugar = {'1': 'Yes', 'Indifferent': 'Indifferent', '0': 'No' }\n",
    "df['LowSugar'] = df['LowSugar'].map(mapping_sugar).astype('category')\n",
    "\n",
    "mapping_cal = {1: 'Yes', 0.0: 'No'}\n",
    "df['HighFiber'] = df['HighFiber'].map(mapping_cal).astype('category')\n",
    "\n",
    "# Remove NA rows and Rating column\n",
    "df = df.drop(\"Rating\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:32:54.028533600Z",
     "start_time": "2024-05-16T12:32:53.859379300Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T12:32:54.923347400Z",
     "start_time": "2024-05-16T12:32:54.800236900Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Diet','RecipeCategory', 'HighCalories', 'LowFat', 'HighFiber', 'HighProtein', 'LowSugar'], drop_first=True)\n",
    "\n",
    "\n",
    "df.rename(columns={\n",
    "    'HighCalories_Yes': 'want_HighCalories',\n",
    "    'LowFat_Yes':'want_LowFat',\n",
    "    'HighFiber_Yes':'want_HighFiber',\n",
    "    'HighProtein_Yes':'want_HighProtein',\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[\"RecipeIngredientParts\"] = df[\"RecipeIngredientParts\"].str.replace(\")\", '')\n",
    "df[\"RecipeIngredientParts\"] = df[\"RecipeIngredientParts\"].str.replace(\"(\", '')\n",
    "df[\"RecipeIngredientParts\"] = df[\"RecipeIngredientParts\"].str.replace(\"\\\"\", '')\n",
    "df[\"RecipeIngredientParts\"] = df[\"RecipeIngredientParts\"].str.replace(\"\\\\\", '')\n",
    "df['RecipeIngredientParts'] = df['RecipeIngredientParts'].str.replace('^c', '', regex=True)\n",
    "\n",
    "def check_keywords(ingredients):\n",
    "    has_animal_product = any(any(keyword in ingredient.lower() for keyword in [\"meat\", \"chicken\", \"lamb\", \"beef\", \"pork\", \"bacon\", \"fish\", \"sausage\", \"turkey\", \"milk\", \"butter\", \"egg\", \"cheese\", \"breast\", \"gelatin\", \"honey\", \"tuna\", \"steak\", \"salmon\"]) for ingredient in ingredients)\n",
    "    has_fish_or_meat = any(any(keyword in ingredient.lower() for keyword in [\"meat\", \"chicken\", \"lamb\", \"beef\", \"pork\", \"bacon\", \"fish\", \"sausage\", \"turkey\", \"tuna\", \"steak\", \"salmon\"]) for ingredient in ingredients)\n",
    "    return has_animal_product, has_fish_or_meat\n",
    "\n",
    "df[['has_animal_product', 'has_fish_meat']] = df['RecipeIngredientParts'].str.split(',').apply(check_keywords).apply(pd.Series)\n",
    "\n",
    "df['for_Vegan'] = ~df['has_animal_product'] & ~df['has_fish_meat']\n",
    "df['for_Vegetarian'] = (df['has_animal_product'] & ~df['has_fish_meat']) | (~df['has_animal_product'] & ~df['has_fish_meat'])\n",
    "df['Correct_Diet'] = (~df['Diet_Vegetarian'] & ~df['Diet_Vegan']) | (df['Diet_Vegan'] & df['for_Vegan']) | (df['Diet_Vegetarian']  & df['for_Vegetarian'] )\n",
    "df[\"DifferenceRequestedAndTimeNeeded\"] = df[\"MaxTime\"] - (df[\"CookTime\"] + df[\"PrepTime\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:33:16.294865500Z",
     "start_time": "2024-05-16T12:32:55.524901200Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Split data into train and test set\n",
    "train_set = df[df[\"TestSetId\"].isna()]\n",
    "test_set = df[df[\"TestSetId\"].notnull()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:33:20.422201Z",
     "start_time": "2024-05-16T12:33:20.358142500Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_set = train_set[train_set[\"Calories\"] < 300000]\n",
    "\n",
    "train_set.dropna(subset=[\"Like\"], inplace=True)\n",
    "train_set = train_set.drop(\"TestSetId\", axis=1)\n",
    "\n",
    "# needs to be done after outlier removal\n",
    "recipesServings_mean = train_set['RecipeServings'].mean()\n",
    "\n",
    "# fill na rows with the mean\n",
    "train_set.loc[:, 'RecipeServings'] = train_set['RecipeServings'].fillna(recipesServings_mean)\n",
    "test_set.loc[:, 'RecipeServings'] = test_set['RecipeServings'].fillna(recipesServings_mean)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:33:21.896546600Z",
     "start_time": "2024-05-16T12:33:21.778439600Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "variables_to_drop = ['CustomerId', 'RecipeId', 'Like', 'Name', 'RecipeIngredientQuantities', 'RecipeIngredientParts', 'RecipeYield','MaxTime', 'for_Vegetarian', 'for_Vegan', 'has_fish_meat', 'has_animal_product', \"Correct_Diet\"]\n",
    "X = train_set.drop(variables_to_drop, axis=1)\n",
    "y = train_set['Like']\n",
    "test_set = test_set.drop(variables_to_drop, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:33:22.796375900Z",
     "start_time": "2024-05-16T12:33:22.764346200Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y,\n",
    "                     test_size=0.3,\n",
    "                     shuffle=True,\n",
    "                     stratify=y,\n",
    "                     random_state=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:33:23.848347900Z",
     "start_time": "2024-05-16T12:33:23.779284400Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=seed)\n",
    "X_train, y_train = oversampler.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:33:24.741160Z",
     "start_time": "2024-05-16T12:33:24.489934Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingClassifier(max_depth=5, n_estimators=400, random_state=2024)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=5, n_estimators=400, random_state=2024)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=5, n_estimators=400, random_state=2024)</pre></div></div></div></div></div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model = GradientBoostingClassifier(n_estimators=400, learning_rate=0.1, max_depth=5, random_state=seed)\n",
    "train_model.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:37:48.790860600Z",
     "start_time": "2024-05-16T12:33:25.400762800Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Like  Predicted_Like  Probability_Like=0  Probability_Like=1\n",
      "93788   False             0.0            0.632850            0.367150\n",
      "87084   False             0.0            0.957647            0.042353\n",
      "46815   False             0.0            0.995348            0.004652\n",
      "98382   False             0.0            0.994071            0.005929\n",
      "119635  False             0.0            0.818047            0.181953\n",
      "...       ...             ...                 ...                 ...\n",
      "88309   False             0.0            0.990746            0.009254\n",
      "103444  False             0.0            0.885927            0.114073\n",
      "91922   False             1.0            0.129914            0.870086\n",
      "116599  False             0.0            0.902247            0.097753\n",
      "127947  False             1.0            0.268874            0.731126\n",
      "\n",
      "[29214 rows x 4 columns]\n",
      "Confusion Matrix:\n",
      "[[21628  3723]\n",
      " [  708  3155]]\n",
      "Test-Precision: 0.4587089270136668\n",
      "Test-Accuracy: 0.8483261449989731\n",
      "Test-Recall: 0.8167227543360083\n",
      "Test Balanced Accuracy: 0.8349323211149885\n"
     ]
    }
   ],
   "source": [
    "test_predictions = train_model.predict(X_test)\n",
    "test_probabilities = train_model.predict_proba(X_test)\n",
    "\n",
    "test_predictions_df = pd.DataFrame({'Like': y_test,\n",
    "                                     'Predicted_Like': test_predictions,\n",
    "                                     'Probability_Like=0': test_probabilities[:, 0],\n",
    "                                     'Probability_Like=1': test_probabilities[:, 1]})\n",
    "print(test_predictions_df)\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Precision, accuracy, recall\n",
    "print(\"Test-Precision:\", precision_score(y_test, test_predictions))\n",
    "print(\"Test-Accuracy:\", accuracy_score(y_test, test_predictions))\n",
    "print(\"Test-Recall:\", recall_score(y_test, test_predictions))\n",
    "print(\"Test Balanced Accuracy:\", balanced_accuracy_score(y_test, test_predictions))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:37:53.422094200Z",
     "start_time": "2024-05-16T12:37:52.826552200Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.8442927044240269\n",
    "0.8494633711829074 mit stratify\n",
    "0.8502350376331118 lr:0.1 ne:400 md:5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_set[\"prediction\"] = train_model.predict(test_set.drop(\"TestSetId\", axis=1))\n",
    "test_output = pd.DataFrame(columns=[\"id\", \"prediction\"])\n",
    "test_output[\"id\"] = test_set[\"TestSetId\"].astype(int)\n",
    "test_output[\"prediction\"] = test_set[\"prediction\"].astype(int)\n",
    "test_output.to_csv(\"predictions_LetsSeePaulAllens'BAC_5.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T14:06:39.987352900Z",
     "start_time": "2024-01-28T14:06:39.602003100Z"
    }
   },
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
